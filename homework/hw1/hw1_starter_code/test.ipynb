{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([[1, 1],\n",
    "        [1, 1],\n",
    "        [1, 1],\n",
    "        [1, 1],\n",
    "        [1, 1],\n",
    "        [1, 1],\n",
    "        [1, 1],\n",
    "        [1, 1]],dtype=float)\n",
    "torch.argmax(a,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5000, 0.5000],\n",
       "        [0.5000, 0.5000],\n",
       "        [0.5000, 0.5000],\n",
       "        [0.5000, 0.5000],\n",
       "        [0.5000, 0.5000],\n",
       "        [0.5000, 0.5000],\n",
       "        [0.5000, 0.5000],\n",
       "        [0.5000, 0.5000]], dtype=torch.float64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = torch.nn.Softmax(dim = -1)\n",
    "layer(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = torch.tensor([[[0.2754, 0.3535, 0.3711],\n",
    "         [0.2115, 0.3784, 0.4101],\n",
    "         [0.2255, 0.3692, 0.4053]],\n",
    "\n",
    "        [[0.2753, 0.3535, 0.3712],\n",
    "         [0.2116, 0.3783, 0.4101],\n",
    "         [0.2256, 0.3692, 0.4052]],\n",
    "\n",
    "        [[0.2754, 0.3535, 0.3711],\n",
    "         [0.2115, 0.3783, 0.4101],\n",
    "         [0.2256, 0.3692, 0.4052]],\n",
    "\n",
    "        [[0.2754, 0.3535, 0.3711],\n",
    "         [0.2115, 0.3783, 0.4101],\n",
    "         [0.2256, 0.3692, 0.4052]]])\n",
    "\n",
    "label = torch.tensor([[[0., 1., 0.],\n",
    "         [1., 0., 0.],\n",
    "         [0., 0., 1.]],\n",
    "\n",
    "        [[1., 0., 0.],\n",
    "         [0., 1., 0.],\n",
    "         [0., 0., 1.]],\n",
    "\n",
    "        [[1., 0., 0.],\n",
    "         [0., 0., 1.],\n",
    "         [0., 1., 0.]],\n",
    "\n",
    "        [[0., 0., 1.],\n",
    "         [1., 0., 0.],\n",
    "         [0., 1., 0.]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(tensor([-0.7948,  0.5969,  0.3107,  1.4373,  2.1345,  0.7679, -0.7456, -0.5533,\n",
      "        -0.7091, -1.2372]), tensor([0, 1])), (tensor([ 0.2503,  0.6591, -0.7134,  2.3174, -0.7257,  0.4743, -0.7589,  0.8243,\n",
      "        -1.4898, -0.2696]), tensor([1, 0]))]\n",
      "tensor(0.6032, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(1.0378, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "Epoch 1: Loss = 0.82049973987435\n",
      "tensor(0.5392, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(0.9922, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "Epoch 2: Loss = 0.7657269559637896\n",
      "tensor(0.5019, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(0.9478, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "Epoch 3: Loss = 0.7248458506852724\n",
      "tensor(0.4700, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(0.9108, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "Epoch 4: Loss = 0.690423609334135\n",
      "tensor(0.4474, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(0.8760, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "Epoch 5: Loss = 0.6617027013191663\n",
      "tensor(0.4323, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(0.8642, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "Epoch 6: Loss = 0.6482635329145529\n",
      "tensor(0.4142, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(0.8537, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "Epoch 7: Loss = 0.6339930696343841\n",
      "tensor(0.3951, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(0.8424, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "Epoch 8: Loss = 0.618702482051767\n",
      "tensor(0.3749, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(0.8320, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "Epoch 9: Loss = 0.6034248388356055\n",
      "tensor(0.3520, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(0.8217, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "Epoch 10: Loss = 0.5868429644223538\n",
      "tensor(0.3268, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(0.8113, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "Epoch 11: Loss = 0.5690336574171294\n",
      "tensor(0.2999, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(0.8004, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "Epoch 12: Loss = 0.5501359628513925\n",
      "tensor(0.2719, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(0.7915, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "Epoch 13: Loss = 0.531695168923334\n",
      "tensor(0.2455, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(0.7762, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "Epoch 14: Loss = 0.5108544115874036\n",
      "tensor(0.2209, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(0.7649, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "Epoch 15: Loss = 0.4929389842912511\n",
      "tensor(0.1965, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(0.7581, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "Epoch 16: Loss = 0.47733398630062085\n",
      "tensor(0.1728, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(0.7510, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "Epoch 17: Loss = 0.46193438857204056\n",
      "tensor(0.1505, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(0.7436, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "Epoch 18: Loss = 0.44706097981478987\n",
      "tensor(0.1301, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(0.7358, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "Epoch 19: Loss = 0.4329456223793907\n",
      "tensor(0.1117, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(0.7287, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "Epoch 20: Loss = 0.4202037530149071\n",
      "tensor(0.0968, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(0.7194, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "Epoch 21: Loss = 0.408064786006955\n",
      "tensor(0.0846, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(0.7107, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "Epoch 22: Loss = 0.39767014796464983\n",
      "tensor(0.0739, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(0.7018, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "Epoch 23: Loss = 0.38785997201055994\n",
      "tensor(0.0646, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(0.6927, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "Epoch 24: Loss = 0.37862627993120235\n",
      "tensor(0.0565, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(0.6834, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "Epoch 25: Loss = 0.36993870891865754\n",
      "tensor(0.0496, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(0.6739, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "Epoch 26: Loss = 0.3617533174311826\n",
      "tensor(0.0436, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(0.6644, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "Epoch 27: Loss = 0.3540200569980574\n",
      "tensor(0.0386, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(0.6548, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "Epoch 28: Loss = 0.34668796778199346\n",
      "tensor(0.0343, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(0.6451, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "Epoch 29: Loss = 0.3397088146215684\n",
      "tensor(0.0307, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(0.6354, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "Epoch 30: Loss = 0.3330389642901947\n",
      "tensor(0.0276, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(0.6257, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "Epoch 31: Loss = 0.32664034324599295\n",
      "tensor(0.0250, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(0.6160, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "Epoch 32: Loss = 0.32048046933782337\n",
      "tensor(0.0227, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(0.6063, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "Epoch 33: Loss = 0.31453216055566136\n",
      "tensor(0.0208, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(0.5967, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "Epoch 34: Loss = 0.3087729123316958\n",
      "tensor(0.0192, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(0.5872, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "Epoch 35: Loss = 0.30318427050344765\n",
      "tensor(0.0177, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(0.5778, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "Epoch 36: Loss = 0.2977511443915421\n",
      "tensor(0.0165, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(0.5684, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "Epoch 37: Loss = 0.2924611993326416\n",
      "tensor(0.0154, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(0.5592, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "Epoch 38: Loss = 0.2873043716073293\n",
      "tensor(0.0144, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(0.5501, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "Epoch 39: Loss = 0.2822723629061714\n",
      "tensor(0.0136, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(0.5411, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "Epoch 40: Loss = 0.2773583168424077\n",
      "tensor(0.0129, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(0.5323, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "Epoch 41: Loss = 0.27255649396782505\n",
      "tensor(0.0122, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(0.5235, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "Epoch 42: Loss = 0.2678620578871973\n",
      "tensor(0.0116, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(0.5150, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "Epoch 43: Loss = 0.2632708543131917\n",
      "tensor(0.0110, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(0.5065, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "Epoch 44: Loss = 0.25877927629191566\n",
      "tensor(0.0106, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(0.4982, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "Epoch 45: Loss = 0.2543841601927264\n",
      "tensor(0.0101, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(0.4900, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "Epoch 46: Loss = 0.25008265817241765\n",
      "tensor(0.0097, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(0.4820, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "Epoch 47: Loss = 0.24587221700396758\n",
      "tensor(0.0093, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(0.4742, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "Epoch 48: Loss = 0.24175047281150344\n",
      "tensor(0.0090, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(0.4664, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "Epoch 49: Loss = 0.2377152240824884\n",
      "tensor(0.0087, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(0.4589, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "Epoch 50: Loss = 0.23376444038817737\n",
      "tensor(0.0084, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(0.4534, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "Epoch 51: Loss = 0.23088519235042904\n",
      "tensor(0.0083, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(0.4441, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "Epoch 52: Loss = 0.22618994991320338\n",
      "tensor(0.0083, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(0.4369, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "Epoch 53: Loss = 0.22262224973579217\n",
      "tensor(0.0083, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(0.4299, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "Epoch 54: Loss = 0.21910311155245663\n",
      "tensor(0.0082, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(0.4230, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "Epoch 55: Loss = 0.2156351697280384\n",
      "tensor(0.0081, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(0.4163, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "Epoch 56: Loss = 0.21222068374810585\n",
      "tensor(0.0080, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(0.4097, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "Epoch 57: Loss = 0.20886147036951455\n",
      "tensor(0.0079, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(0.4032, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "Epoch 58: Loss = 0.205558948746606\n",
      "tensor(0.0078, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(0.3969, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "Epoch 59: Loss = 0.20231415233233038\n",
      "tensor(0.0076, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(0.3907, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "Epoch 60: Loss = 0.19912778609609333\n",
      "tensor(0.0074, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(0.3846, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "Epoch 61: Loss = 0.19600021211420188\n",
      "tensor(0.0073, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(0.3786, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "Epoch 62: Loss = 0.1929315428889358\n",
      "tensor(0.0071, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(0.3728, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "Epoch 63: Loss = 0.18992165223991897\n",
      "tensor(0.0069, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(0.3670, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "Epoch 64: Loss = 0.1869702252199696\n",
      "tensor(0.0067, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(0.3614, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "Epoch 65: Loss = 0.18407675748713062\n",
      "tensor(0.0066, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(0.3559, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "Epoch 66: Loss = 0.1812406199176976\n",
      "tensor(0.0064, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(0.3505, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "Epoch 67: Loss = 0.1784610768982576\n",
      "tensor(0.0062, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(0.3452, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "Epoch 68: Loss = 0.1757372968169023\n",
      "tensor(0.0061, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(0.3401, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "Epoch 69: Loss = 0.17306837994554855\n",
      "tensor(0.0059, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(0.3350, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "Epoch 70: Loss = 0.17045337184097992\n",
      "tensor(0.0058, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(0.3300, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "Epoch 71: Loss = 0.16789128380792212\n",
      "tensor(0.0056, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(0.3251, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "Epoch 72: Loss = 0.16538108263337953\n",
      "tensor(0.0055, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(0.3204, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "Epoch 73: Loss = 0.16292174776877377\n",
      "tensor(0.0053, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(0.3157, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "Epoch 74: Loss = 0.1605122215540897\n",
      "tensor(0.0052, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(0.3111, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "Epoch 75: Loss = 0.1581514571793459\n",
      "tensor(0.0051, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(0.3066, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "Epoch 76: Loss = 0.15583841375391536\n",
      "tensor(0.0049, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(0.3022, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "Epoch 77: Loss = 0.15357204809360453\n",
      "tensor(0.0048, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(0.2979, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "Epoch 78: Loss = 0.15135132190374403\n",
      "tensor(0.0047, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(0.2936, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "Epoch 79: Loss = 0.1491752073726099\n",
      "tensor(0.0046, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(0.2895, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "Epoch 80: Loss = 0.14704269979523069\n",
      "tensor(0.0045, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(0.2854, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "Epoch 81: Loss = 0.1449528257561701\n",
      "tensor(0.0044, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(0.2814, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "Epoch 82: Loss = 0.14290459827182586\n",
      "tensor(0.0043, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(0.2775, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "Epoch 83: Loss = 0.14089705959789728\n",
      "tensor(0.0042, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(0.2737, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "Epoch 84: Loss = 0.13892928430514445\n",
      "tensor(0.0041, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(0.2699, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "Epoch 85: Loss = 0.13700034741181347\n",
      "tensor(0.0040, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(0.2662, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "Epoch 86: Loss = 0.13510936533229442\n",
      "tensor(0.0039, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(0.2626, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "Epoch 87: Loss = 0.13325544738478787\n",
      "tensor(0.0038, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(0.2590, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "Epoch 88: Loss = 0.13143773952706495\n",
      "tensor(0.0038, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(0.2555, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "Epoch 89: Loss = 0.129655401361048\n",
      "tensor(0.0037, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(0.2521, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "Epoch 90: Loss = 0.12790762289061677\n",
      "tensor(0.0036, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(0.2488, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "Epoch 91: Loss = 0.12619359018914114\n",
      "tensor(0.0035, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(0.2455, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "Epoch 92: Loss = 0.12451252933620953\n",
      "tensor(0.0035, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(0.2423, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "Epoch 93: Loss = 0.12286368736116189\n",
      "tensor(0.0034, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(0.2391, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "Epoch 94: Loss = 0.12124630768093234\n",
      "tensor(0.0033, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(0.2360, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "Epoch 95: Loss = 0.11965967294943325\n",
      "tensor(0.0033, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(0.2329, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "Epoch 96: Loss = 0.11810307156757334\n",
      "tensor(0.0032, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(0.2299, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "Epoch 97: Loss = 0.11657581901160179\n",
      "tensor(0.0031, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(0.2270, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "Epoch 98: Loss = 0.1150772276613756\n",
      "tensor(0.0031, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(0.2241, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "Epoch 99: Loss = 0.11360665352469494\n",
      "tensor(0.0030, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(0.2213, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "Epoch 100: Loss = 0.11216345213262745\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define the neural network class\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(10, 5)  # Fully connected layer 1\n",
    "        self.fc2 = nn.Linear(5, 2)   # Fully connected layer 2\n",
    "        self.fc3 = nn.Linear(2,1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))  # Apply ReLU activation to fc1\n",
    "        x = self.fc2(x)       # Output layer\n",
    "        return x\n",
    "\n",
    "# Create an instance of the network\n",
    "net = NeuralNetwork()\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = torch.nn.functional.cross_entropy\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.01)\n",
    "\n",
    "# Define the training data\n",
    "train_data = [\n",
    "    (torch.randn(10), torch.tensor([0,1])),\n",
    "    (torch.randn(10), torch.tensor([1,0])),\n",
    "    # Add more training data here\n",
    "]\n",
    "print(train_data)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(100):  # Number of epochs\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for inputs, labels in train_data:\n",
    "        # Zero the gradients\n",
    "        labels = torch.as_tensor(labels,dtype=float)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = net(inputs)\n",
    "        outputs = torch.as_tensor(outputs,dtype=float)\n",
    "        \n",
    "        # Compute the loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        print(torch.norm(loss))\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update the running loss\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    # Print the average loss for each epoch\n",
    "    print(f\"Epoch {epoch+1}: Loss = {running_loss / len(train_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
