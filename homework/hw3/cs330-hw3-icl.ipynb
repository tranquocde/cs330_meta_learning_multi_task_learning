{"cells":[{"cell_type":"code","execution_count":17,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-10-30T16:41:37.853698Z","iopub.status.busy":"2023-10-30T16:41:37.853307Z","iopub.status.idle":"2023-10-30T16:41:37.871314Z","shell.execute_reply":"2023-10-30T16:41:37.870422Z","shell.execute_reply.started":"2023-10-30T16:41:37.853661Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["/kaggle/input/files-import-final/utils.py\n","/kaggle/input/files-import-final/requirements.txt\n","/kaggle/input/files-import-final/icl.py\n","/kaggle/input/files-import-final/ft.py\n"]}],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":32,"metadata":{"execution":{"iopub.execute_input":"2023-10-30T17:54:23.898710Z","iopub.status.busy":"2023-10-30T17:54:23.897789Z","iopub.status.idle":"2023-10-30T17:54:23.903628Z","shell.execute_reply":"2023-10-30T17:54:23.902697Z","shell.execute_reply.started":"2023-10-30T17:54:23.898658Z"},"trusted":true},"outputs":[],"source":["import os\n","os.chdir('/kaggle/working/files-import-final')"]},{"cell_type":"code","execution_count":33,"metadata":{"execution":{"iopub.execute_input":"2023-10-30T17:54:25.432374Z","iopub.status.busy":"2023-10-30T17:54:25.431662Z","iopub.status.idle":"2023-10-30T17:54:25.437381Z","shell.execute_reply":"2023-10-30T17:54:25.436366Z","shell.execute_reply.started":"2023-10-30T17:54:25.432338Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["/kaggle/working/files-import-final\n"]}],"source":["import os\n","\n","# Get the current working directory\n","current_directory = os.getcwd()\n","\n","print(current_directory)"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2023-10-30T16:41:37.893560Z","iopub.status.busy":"2023-10-30T16:41:37.893303Z","iopub.status.idle":"2023-10-30T16:41:38.873714Z","shell.execute_reply":"2023-10-30T16:41:38.872678Z","shell.execute_reply.started":"2023-10-30T16:41:37.893529Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["__pycache__  ft.py  icl.py  requirements.txt  results  utils.py\n"]}],"source":["!ls"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2023-10-30T16:41:38.875865Z","iopub.status.busy":"2023-10-30T16:41:38.875520Z","iopub.status.idle":"2023-10-30T17:53:15.979904Z","shell.execute_reply":"2023-10-30T17:53:15.978820Z","shell.execute_reply.started":"2023-10-30T16:41:38.875831Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Loading model med...\n","Loading dataset xsum...\n","Running in-context learning with med on xsum with k=0 and prompt_mode=none\n","Eval: 0.1517: 100%|███████████████████████████| 125/125 [01:10<00:00,  1.78it/s]\n","Evaluation results: {'med_xsum_0_none': 0.15172203526933503}\n","Running in-context learning with med on xsum with k=1 and prompt_mode=none\n","Eval: 0.1339: 100%|███████████████████████████| 125/125 [01:59<00:00,  1.04it/s]\n","Evaluation results: {'med_xsum_1_none': 0.13394519615253592}\n","Running in-context learning with med on xsum with k=4 and prompt_mode=none\n","Eval: 0.1511: 100%|███████████████████████████| 125/125 [04:02<00:00,  1.94s/it]\n","Evaluation results: {'med_xsum_4_none': 0.1511430218852229}\n","Running in-context learning with med on xsum with k=0 and prompt_mode=tldr\n","Eval: 0.1967: 100%|███████████████████████████| 125/125 [00:53<00:00,  2.36it/s]\n","Evaluation results: {'med_xsum_0_tldr': 0.1967317434379297}\n","Running in-context learning with med on xsum with k=1 and prompt_mode=tldr\n","Eval: 0.1708: 100%|███████████████████████████| 125/125 [01:34<00:00,  1.32it/s]\n","Evaluation results: {'med_xsum_1_tldr': 0.17084408544417168}\n","Running in-context learning with med on xsum with k=4 and prompt_mode=tldr\n","Eval: 0.1849: 100%|███████████████████████████| 125/125 [02:40<00:00,  1.29s/it]\n","Evaluation results: {'med_xsum_4_tldr': 0.18487605526055875}\n","Running in-context learning with med on xsum with k=0 and prompt_mode=custom\n","Eval: 0.0858: 100%|███████████████████████████| 125/125 [00:42<00:00,  2.92it/s]\n","Evaluation results: {'med_xsum_0_custom': 0.08577057593161051}\n","Running in-context learning with med on xsum with k=1 and prompt_mode=custom\n","Eval: 0.1888: 100%|███████████████████████████| 125/125 [01:46<00:00,  1.17it/s]\n","Evaluation results: {'med_xsum_1_custom': 0.18883134168384164}\n","Running in-context learning with med on xsum with k=4 and prompt_mode=custom\n","Eval: 0.1672: 100%|███████████████████████████| 125/125 [03:56<00:00,  1.89s/it]\n","Evaluation results: {'med_xsum_4_custom': 0.1671720099705164}\n","Loading model full...\n","Loading dataset xsum...\n","Running in-context learning with full on xsum with k=0 and prompt_mode=none\n","Eval: 0.1408: 100%|███████████████████████████| 125/125 [03:15<00:00,  1.57s/it]\n","Evaluation results: {'full_xsum_0_none': 0.14079444037049826}\n","Running in-context learning with full on xsum with k=1 and prompt_mode=none\n","Eval: 0.1383: 100%|███████████████████████████| 125/125 [05:22<00:00,  2.58s/it]\n","Evaluation results: {'full_xsum_1_none': 0.13827718195375868}\n","Running in-context learning with full on xsum with k=4 and prompt_mode=none\n","Eval: 0.1348: 100%|███████████████████████████| 125/125 [11:51<00:00,  5.69s/it]\n","Evaluation results: {'full_xsum_4_none': 0.1348176987857}\n","Running in-context learning with full on xsum with k=0 and prompt_mode=tldr\n","Eval: 0.2039: 100%|███████████████████████████| 125/125 [02:38<00:00,  1.27s/it]\n","Evaluation results: {'full_xsum_0_tldr': 0.20392942037129969}\n","Running in-context learning with full on xsum with k=1 and prompt_mode=tldr\n","Eval: 0.2375: 100%|███████████████████████████| 125/125 [05:51<00:00,  2.81s/it]\n","Evaluation results: {'full_xsum_1_tldr': 0.23752913408547788}\n","Running in-context learning with full on xsum with k=4 and prompt_mode=tldr\n","Eval: 0.2228: 100%|███████████████████████████| 125/125 [14:02<00:00,  6.74s/it]\n","Evaluation results: {'full_xsum_4_tldr': 0.22281953849838965}\n","Running in-context learning with full on xsum with k=0 and prompt_mode=custom\n","Eval: 0.1381: 100%|███████████████████████████| 125/125 [02:45<00:00,  1.32s/it]\n","Evaluation results: {'full_xsum_0_custom': 0.13806128168733042}\n","Running in-context learning with full on xsum with k=1 and prompt_mode=custom\n","Eval: 0.1954: 100%|███████████████████████████| 125/125 [06:15<00:00,  3.00s/it]\n","Evaluation results: {'full_xsum_1_custom': 0.1953731269436339}\n","Running in-context learning with full on xsum with k=4 and prompt_mode=custom\n","Eval: 0.2500:   1%|▏                            | 1/125 [00:06<12:40,  6.13s/it]^C\n","Eval: 0.2500:   1%|▏                            | 1/125 [00:10<21:27, 10.38s/it]\n","Traceback (most recent call last):\n","  File \"/kaggle/working/files-import-final/icl.py\", line 259, in <module>\n","    run()\n","  File \"/kaggle/working/files-import-final/icl.py\", line 252, in run\n","    run_icl(args.model.split(','), args.dataset.split(','), ks, args.prompt.split(','))\n","  File \"/kaggle/working/files-import-final/icl.py\", line 195, in run_icl\n","    sampled_tokens = do_sample(model, encoded_prompts.input_ids, stop_tokens, max_tokens) # using pretrained model to do sampling\n","  File \"/kaggle/working/files-import-final/icl.py\", line 138, in do_sample\n","    outputs = model(input_ids=input_ids)\n","  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n","    return forward_call(*input, **kwargs)\n","  File \"/opt/conda/lib/python3.10/site-packages/transformers/models/gpt2/modeling_gpt2.py\", line 1046, in forward\n","    transformer_outputs = self.transformer(\n","  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n","    return forward_call(*input, **kwargs)\n","  File \"/opt/conda/lib/python3.10/site-packages/transformers/models/gpt2/modeling_gpt2.py\", line 889, in forward\n","    outputs = block(\n","  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n","    return forward_call(*input, **kwargs)\n","  File \"/opt/conda/lib/python3.10/site-packages/transformers/models/gpt2/modeling_gpt2.py\", line 389, in forward\n","    attn_outputs = self.attn(\n","  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n","    return forward_call(*input, **kwargs)\n","  File \"/opt/conda/lib/python3.10/site-packages/transformers/models/gpt2/modeling_gpt2.py\", line 330, in forward\n","    attn_output, attn_weights = self._attn(query, key, value, attention_mask, head_mask)\n","  File \"/opt/conda/lib/python3.10/site-packages/transformers/models/gpt2/modeling_gpt2.py\", line 185, in _attn\n","    attn_weights = attn_weights / torch.tensor(\n","KeyboardInterrupt\n"]}],"source":["!python icl.py --task icl --model med,full --dataset xsum --k 0,1,4  --prompt none,tldr,custom\n"]},{"cell_type":"code","execution_count":34,"metadata":{"execution":{"iopub.execute_input":"2023-10-30T17:54:30.826153Z","iopub.status.busy":"2023-10-30T17:54:30.825807Z","iopub.status.idle":"2023-10-30T17:54:35.303447Z","shell.execute_reply":"2023-10-30T17:54:35.302193Z","shell.execute_reply.started":"2023-10-30T17:54:30.826116Z"},"trusted":true},"outputs":[],"source":["!python3 icl.py --task plot --model med,full --dataset xsum --k 0,1,4  --prompt none,tldr"]},{"cell_type":"code","execution_count":35,"metadata":{"execution":{"iopub.execute_input":"2023-10-30T17:55:30.571897Z","iopub.status.busy":"2023-10-30T17:55:30.571522Z","iopub.status.idle":"2023-10-30T18:27:25.990280Z","shell.execute_reply":"2023-10-30T18:27:25.989097Z","shell.execute_reply.started":"2023-10-30T17:55:30.571864Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading: 100%|███████████████████████████| 548M/548M [00:07<00:00, 73.2MB/s]\n","Downloading: 100%|█████████████████████████| 1.04M/1.04M [00:00<00:00, 14.8MB/s]\n","Downloading: 100%|███████████████████████████| 456k/456k [00:00<00:00, 2.44MB/s]\n","Downloading: 100%|█████████████████████████| 1.36M/1.36M [00:00<00:00, 10.5MB/s]\n","Fine-tuning small on xsum with k=0 and mode=first\n","Eval: 0.1722: 100%|███████████████████████████| 125/125 [00:26<00:00,  4.73it/s]\n","{'small_xsum_0_first': 0.1721843674278898}\n","Fine-tuning small on xsum with k=1 and mode=first\n","Fine-tuning acc: 0.3636: 100%|██████████████████| 10/10 [00:00<00:00, 17.18it/s]\n","Eval: 0.1768: 100%|███████████████████████████| 125/125 [00:26<00:00,  4.79it/s]\n","{'small_xsum_1_first': 0.17683379072643562}\n","Fine-tuning small on xsum with k=8 and mode=first\n","Fine-tuning acc: 0.0417: 100%|██████████████████| 80/80 [00:03<00:00, 21.44it/s]\n","Eval: 0.2040: 100%|███████████████████████████| 125/125 [00:30<00:00,  4.15it/s]\n","{'small_xsum_8_first': 0.20404528479258213}\n","Fine-tuning small on xsum with k=128 and mode=first\n","Fine-tuning acc: 0.0033: 100%|██████████████| 1280/1280 [02:06<00:00, 10.14it/s]\n","Eval: 0.2378: 100%|███████████████████████████| 125/125 [00:30<00:00,  4.05it/s]\n","{'small_xsum_128_first': 0.23777223514210355}\n","Fine-tuning small on xsum with k=0 and mode=last\n","Eval: 0.1722: 100%|███████████████████████████| 125/125 [00:26<00:00,  4.77it/s]\n","{'small_xsum_0_last': 0.1721843674278898}\n","Fine-tuning small on xsum with k=1 and mode=last\n","Fine-tuning acc: 0.3636: 100%|██████████████████| 10/10 [00:00<00:00, 22.58it/s]\n","Eval: 0.1769: 100%|███████████████████████████| 125/125 [00:25<00:00,  4.84it/s]\n","{'small_xsum_1_last': 0.17694074188121586}\n","Fine-tuning small on xsum with k=8 and mode=last\n","Fine-tuning acc: 0.0417: 100%|██████████████████| 80/80 [00:03<00:00, 21.39it/s]\n","Eval: 0.1839: 100%|███████████████████████████| 125/125 [00:25<00:00,  4.81it/s]\n","{'small_xsum_8_last': 0.18388366300045605}\n","Fine-tuning small on xsum with k=128 and mode=last\n","Fine-tuning acc: 0.0031: 100%|██████████████| 1280/1280 [02:06<00:00, 10.10it/s]\n","Eval: 0.2173: 100%|███████████████████████████| 125/125 [00:26<00:00,  4.65it/s]\n","{'small_xsum_128_last': 0.2172755744938279}\n","Fine-tuning small on xsum with k=0 and mode=middle\n","Eval: 0.1722: 100%|███████████████████████████| 125/125 [00:26<00:00,  4.73it/s]\n","{'small_xsum_0_middle': 0.1721843674278898}\n","Fine-tuning small on xsum with k=1 and mode=middle\n","Fine-tuning acc: 0.3636: 100%|██████████████████| 10/10 [00:00<00:00, 22.20it/s]\n","Eval: 0.1789: 100%|███████████████████████████| 125/125 [00:25<00:00,  4.88it/s]\n","{'small_xsum_1_middle': 0.1789279242810837}\n","Fine-tuning small on xsum with k=8 and mode=middle\n","Fine-tuning acc: 0.0417: 100%|██████████████████| 80/80 [00:03<00:00, 21.50it/s]\n","Eval: 0.2042: 100%|███████████████████████████| 125/125 [00:27<00:00,  4.52it/s]\n","{'small_xsum_8_middle': 0.2042002689458417}\n","Fine-tuning small on xsum with k=128 and mode=middle\n","Fine-tuning acc: 0.0029: 100%|██████████████| 1280/1280 [02:06<00:00, 10.13it/s]\n","Eval: 0.2525: 100%|███████████████████████████| 125/125 [00:26<00:00,  4.66it/s]\n","{'small_xsum_128_middle': 0.2524645705708215}\n","Fine-tuning small on xsum with k=0 and mode=lora4\n","Eval: 0.1722: 100%|███████████████████████████| 125/125 [00:26<00:00,  4.76it/s]\n","{'small_xsum_0_lora4': 0.1721843674278898}\n","Fine-tuning small on xsum with k=1 and mode=lora4\n","Fine-tuning acc: 0.3636: 100%|██████████████████| 10/10 [00:00<00:00, 18.09it/s]\n","Eval: 0.1722: 100%|███████████████████████████| 125/125 [00:31<00:00,  3.98it/s]\n","{'small_xsum_1_lora4': 0.1721843674278898}\n","Fine-tuning small on xsum with k=8 and mode=lora4\n","Fine-tuning acc: 0.0417: 100%|██████████████████| 80/80 [00:04<00:00, 18.04it/s]\n","Eval: 0.1740: 100%|███████████████████████████| 125/125 [00:31<00:00,  3.94it/s]\n","{'small_xsum_8_lora4': 0.17403760752112993}\n","Fine-tuning small on xsum with k=128 and mode=lora4\n","Fine-tuning acc: 0.0029: 100%|██████████████| 1280/1280 [02:27<00:00,  8.69it/s]\n","Eval: 0.1818: 100%|███████████████████████████| 125/125 [00:31<00:00,  4.03it/s]\n","{'small_xsum_128_lora4': 0.18184694397031428}\n","Fine-tuning small on xsum with k=0 and mode=lora16\n","Eval: 0.1722: 100%|███████████████████████████| 125/125 [00:26<00:00,  4.79it/s]\n","{'small_xsum_0_lora16': 0.1721843674278898}\n","Fine-tuning small on xsum with k=1 and mode=lora16\n","Fine-tuning acc: 0.3636: 100%|██████████████████| 10/10 [00:00<00:00, 18.74it/s]\n","Eval: 0.1721: 100%|███████████████████████████| 125/125 [00:31<00:00,  3.93it/s]\n","{'small_xsum_1_lora16': 0.17207770076122317}\n","Fine-tuning small on xsum with k=8 and mode=lora16\n","Fine-tuning acc: 0.0417: 100%|██████████████████| 80/80 [00:04<00:00, 17.73it/s]\n","Eval: 0.1787: 100%|███████████████████████████| 125/125 [00:31<00:00,  3.91it/s]\n","{'small_xsum_8_lora16': 0.17873364451325793}\n","Fine-tuning small on xsum with k=128 and mode=lora16\n","Fine-tuning acc: 0.0029: 100%|██████████████| 1280/1280 [02:27<00:00,  8.66it/s]\n","Eval: 0.1920: 100%|███████████████████████████| 125/125 [00:31<00:00,  4.02it/s]\n","{'small_xsum_128_lora16': 0.19195706769003984}\n","Downloading builder script: 100%|██████████| 41.3k/41.3k [00:00<00:00, 6.51MB/s]\n","Downloading metadata: 100%|██████████████████| 369k/369k [00:00<00:00, 1.93MB/s]\n","Downloading and preparing dataset babi_qa/en-valid-10k-qa1 (download: 14.99 MiB, generated: 1.74 MiB, post-processed: Unknown size, total: 16.73 MiB) to /root/.cache/huggingface/datasets/babi_qa/en-valid-10k-qa1/1.2.0/a3c1ff28a1e13b872a34a5aae4a0d6715f4ff95cbc823c7d2c04f278e912dfab...\n","Downloading data: 100%|████████████████████| 15.7M/15.7M [00:02<00:00, 6.29MB/s]\n","Dataset babi_qa downloaded and prepared to /root/.cache/huggingface/datasets/babi_qa/en-valid-10k-qa1/1.2.0/a3c1ff28a1e13b872a34a5aae4a0d6715f4ff95cbc823c7d2c04f278e912dfab. Subsequent calls will reuse this data.\n","Fine-tuning small on babi with k=0 and mode=first\n","Eval: 0.4640: 100%|███████████████████████████| 125/125 [00:03<00:00, 40.77it/s]\n","{'small_babi_0_first': 0.464}\n","Fine-tuning small on babi with k=1 and mode=first\n","Fine-tuning acc: 0.5000: 100%|██████████████████| 10/10 [00:00<00:00, 22.74it/s]\n","Eval: 0.5040: 100%|███████████████████████████| 125/125 [00:02<00:00, 47.90it/s]\n","{'small_babi_1_first': 0.504}\n","Fine-tuning small on babi with k=8 and mode=first\n","Fine-tuning acc: 0.3750: 100%|██████████████████| 80/80 [00:03<00:00, 22.58it/s]\n","Eval: 0.5840: 100%|███████████████████████████| 125/125 [00:02<00:00, 53.06it/s]\n","{'small_babi_8_first': 0.584}\n","Fine-tuning small on babi with k=128 and mode=first\n","Fine-tuning acc: 0.0312: 100%|██████████████| 1280/1280 [01:32<00:00, 13.82it/s]\n","Eval: 0.5840: 100%|███████████████████████████| 125/125 [00:02<00:00, 53.46it/s]\n","{'small_babi_128_first': 0.584}\n","Fine-tuning small on babi with k=0 and mode=last\n","Eval: 0.4640: 100%|███████████████████████████| 125/125 [00:03<00:00, 41.66it/s]\n","{'small_babi_0_last': 0.464}\n","Fine-tuning small on babi with k=1 and mode=last\n","Fine-tuning acc: 0.5000: 100%|██████████████████| 10/10 [00:00<00:00, 23.29it/s]\n","Eval: 0.4800: 100%|███████████████████████████| 125/125 [00:02<00:00, 44.90it/s]\n","{'small_babi_1_last': 0.48}\n","Fine-tuning small on babi with k=8 and mode=last\n","Fine-tuning acc: 0.3750: 100%|██████████████████| 80/80 [00:03<00:00, 22.59it/s]\n","Eval: 0.5440: 100%|███████████████████████████| 125/125 [00:02<00:00, 53.89it/s]\n","{'small_babi_8_last': 0.544}\n","Fine-tuning small on babi with k=128 and mode=last\n","Fine-tuning acc: 0.0352: 100%|██████████████| 1280/1280 [01:32<00:00, 13.86it/s]\n","Eval: 0.5840: 100%|███████████████████████████| 125/125 [00:02<00:00, 53.45it/s]\n","{'small_babi_128_last': 0.584}\n","Fine-tuning small on babi with k=0 and mode=middle\n","Eval: 0.4640: 100%|███████████████████████████| 125/125 [00:02<00:00, 42.54it/s]\n","{'small_babi_0_middle': 0.464}\n","Fine-tuning small on babi with k=1 and mode=middle\n","Fine-tuning acc: 0.5000: 100%|██████████████████| 10/10 [00:00<00:00, 23.24it/s]\n","Eval: 0.5280: 100%|███████████████████████████| 125/125 [00:02<00:00, 52.86it/s]\n","{'small_babi_1_middle': 0.528}\n","Fine-tuning small on babi with k=8 and mode=middle\n","Fine-tuning acc: 0.3750: 100%|██████████████████| 80/80 [00:03<00:00, 22.75it/s]\n","Eval: 0.5760: 100%|███████████████████████████| 125/125 [00:02<00:00, 54.48it/s]\n","{'small_babi_8_middle': 0.576}\n","Fine-tuning small on babi with k=128 and mode=middle\n","Fine-tuning acc: 0.0352: 100%|██████████████| 1280/1280 [01:32<00:00, 13.82it/s]\n","Eval: 0.6160: 100%|███████████████████████████| 125/125 [00:02<00:00, 54.11it/s]\n","{'small_babi_128_middle': 0.616}\n","Fine-tuning small on babi with k=0 and mode=lora4\n","Eval: 0.4640: 100%|███████████████████████████| 125/125 [00:03<00:00, 41.28it/s]\n","{'small_babi_0_lora4': 0.464}\n","Fine-tuning small on babi with k=1 and mode=lora4\n","Fine-tuning acc: 0.5000: 100%|██████████████████| 10/10 [00:00<00:00, 18.76it/s]\n","Eval: 0.4640: 100%|███████████████████████████| 125/125 [00:03<00:00, 32.42it/s]\n","{'small_babi_1_lora4': 0.464}\n","Fine-tuning small on babi with k=8 and mode=lora4\n","Fine-tuning acc: 0.3125: 100%|██████████████████| 80/80 [00:04<00:00, 18.68it/s]\n","Eval: 0.4720: 100%|███████████████████████████| 125/125 [00:03<00:00, 32.54it/s]\n","{'small_babi_8_lora4': 0.472}\n","Fine-tuning small on babi with k=128 and mode=lora4\n","Fine-tuning acc: 0.0352: 100%|██████████████| 1280/1280 [01:53<00:00, 11.29it/s]\n","Eval: 0.5520: 100%|███████████████████████████| 125/125 [00:02<00:00, 42.17it/s]\n","{'small_babi_128_lora4': 0.552}\n","Fine-tuning small on babi with k=0 and mode=lora16\n","Eval: 0.4640: 100%|███████████████████████████| 125/125 [00:02<00:00, 42.53it/s]\n","{'small_babi_0_lora16': 0.464}\n","Fine-tuning small on babi with k=1 and mode=lora16\n","Fine-tuning acc: 0.5000: 100%|██████████████████| 10/10 [00:00<00:00, 18.50it/s]\n","Eval: 0.4640: 100%|███████████████████████████| 125/125 [00:03<00:00, 32.36it/s]\n","{'small_babi_1_lora16': 0.464}\n","Fine-tuning small on babi with k=8 and mode=lora16\n","Fine-tuning acc: 0.3125: 100%|██████████████████| 80/80 [00:04<00:00, 19.03it/s]\n","Eval: 0.5040: 100%|███████████████████████████| 125/125 [00:03<00:00, 34.63it/s]\n","{'small_babi_8_lora16': 0.504}\n","Fine-tuning small on babi with k=128 and mode=lora16\n","Fine-tuning acc: 0.0352: 100%|██████████████| 1280/1280 [01:53<00:00, 11.25it/s]\n","Eval: 0.6080: 100%|███████████████████████████| 125/125 [00:03<00:00, 41.58it/s]\n","{'small_babi_128_lora16': 0.608}\n"]}],"source":["!python ft.py --task ft --model small --mode first,last,middle,lora4,lora16 --dataset xsum,babi --k 0,1,8,128 \n"]},{"cell_type":"code","execution_count":38,"metadata":{"execution":{"iopub.execute_input":"2023-10-30T18:29:11.033908Z","iopub.status.busy":"2023-10-30T18:29:11.032990Z","iopub.status.idle":"2023-10-30T18:29:15.408587Z","shell.execute_reply":"2023-10-30T18:29:15.407506Z","shell.execute_reply.started":"2023-10-30T18:29:11.033870Z"},"trusted":true},"outputs":[],"source":["!python ft.py --task plot --model small --mode first,last,middle,lora4,lora16 --dataset babi --k 0,1,8,128"]},{"cell_type":"code","execution_count":39,"metadata":{"execution":{"iopub.execute_input":"2023-10-30T18:29:23.455761Z","iopub.status.busy":"2023-10-30T18:29:23.454994Z","iopub.status.idle":"2023-10-30T18:29:27.836560Z","shell.execute_reply":"2023-10-30T18:29:27.835463Z","shell.execute_reply.started":"2023-10-30T18:29:23.455725Z"},"trusted":true},"outputs":[],"source":["!python ft.py --task plot --model small --mode first,last,middle,lora4,lora16 --dataset xsum --k 0,1,8,128"]},{"cell_type":"code","execution_count":40,"metadata":{"execution":{"iopub.execute_input":"2023-10-30T18:29:28.990430Z","iopub.status.busy":"2023-10-30T18:29:28.990040Z","iopub.status.idle":"2023-10-30T18:29:29.916753Z","shell.execute_reply":"2023-10-30T18:29:29.915685Z","shell.execute_reply.started":"2023-10-30T18:29:28.990394Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":[" __pycache__\n"," ft.py\n","'ft_babi_[0, 1, 8, 128]_modes.png'\n","'ft_xsum_[0, 1, 8, 128]_modes.png'\n"," icl.py\n","'icl_xsum_[0, 1, 4]_['\\''none'\\'', '\\''tldr'\\''].png'\n"," requirements.txt\n"," results\n"," utils.py\n"]}],"source":["!ls"]},{"cell_type":"code","execution_count":41,"metadata":{"execution":{"iopub.execute_input":"2023-10-30T18:29:34.026046Z","iopub.status.busy":"2023-10-30T18:29:34.025656Z","iopub.status.idle":"2023-10-30T18:29:34.030873Z","shell.execute_reply":"2023-10-30T18:29:34.029920Z","shell.execute_reply.started":"2023-10-30T18:29:34.026010Z"},"trusted":true},"outputs":[],"source":["import os\n","os.chdir('/kaggle/working')"]},{"cell_type":"code","execution_count":42,"metadata":{"execution":{"iopub.execute_input":"2023-10-30T18:29:36.205361Z","iopub.status.busy":"2023-10-30T18:29:36.204525Z","iopub.status.idle":"2023-10-30T18:29:37.132684Z","shell.execute_reply":"2023-10-30T18:29:37.131556Z","shell.execute_reply.started":"2023-10-30T18:29:36.205331Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["files-import-final  output_1.tar.gz\n"]}],"source":["!ls"]},{"cell_type":"code","execution_count":43,"metadata":{"execution":{"iopub.execute_input":"2023-10-30T18:29:41.774158Z","iopub.status.busy":"2023-10-30T18:29:41.773300Z","iopub.status.idle":"2023-10-30T18:29:42.736032Z","shell.execute_reply":"2023-10-30T18:29:42.734953Z","shell.execute_reply.started":"2023-10-30T18:29:41.774104Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["files-import-final/\n","files-import-final/results/\n","files-import-final/results/ft/\n","files-import-final/results/ft/small_xsum_0_middle.json\n","files-import-final/results/ft/small_babi_1_lora16.json\n","files-import-final/results/ft/small_babi_1_first.json\n","files-import-final/results/ft/small_xsum_8_middle.json\n","files-import-final/results/ft/small_xsum_1_middle.json\n","files-import-final/results/ft/small_xsum_0_last.json\n","files-import-final/results/ft/small_babi_128_lora4.json\n","files-import-final/results/ft/small_xsum_8_lora16.json\n","files-import-final/results/ft/small_xsum_8_last.json\n","files-import-final/results/ft/small_xsum_8_lora4.json\n","files-import-final/results/ft/small_babi_128_lora16.json\n","files-import-final/results/ft/small_babi_8_first.json\n","files-import-final/results/ft/small_babi_128_last.json\n","files-import-final/results/ft/small_babi_0_lora4.json\n","files-import-final/results/ft/small_babi_1_middle.json\n","files-import-final/results/ft/small_xsum_128_lora4.json\n","files-import-final/results/ft/small_babi_0_middle.json\n","files-import-final/results/ft/small_babi_128_first.json\n","files-import-final/results/ft/small_xsum_0_lora16.json\n","files-import-final/results/ft/small_babi_0_first.json\n","files-import-final/results/ft/small_babi_0_lora16.json\n","files-import-final/results/ft/small_babi_1_last.json\n","files-import-final/results/ft/small_xsum_1_lora4.json\n","files-import-final/results/ft/small_xsum_1_last.json\n","files-import-final/results/ft/small_xsum_128_middle.json\n","files-import-final/results/ft/small_xsum_128_last.json\n","files-import-final/results/ft/small_babi_128_middle.json\n","files-import-final/results/ft/small_babi_8_lora4.json\n","files-import-final/results/ft/small_xsum_0_first.json\n","files-import-final/results/ft/small_babi_8_middle.json\n","files-import-final/results/ft/small_xsum_1_first.json\n","files-import-final/results/ft/small_xsum_1_lora16.json\n","files-import-final/results/ft/small_babi_1_lora4.json\n","files-import-final/results/ft/small_babi_8_lora16.json\n","files-import-final/results/ft/small_xsum_128_lora16.json\n","files-import-final/results/ft/small_babi_8_last.json\n","files-import-final/results/ft/small_xsum_8_first.json\n","files-import-final/results/ft/small_xsum_0_lora4.json\n","files-import-final/results/ft/small_babi_0_last.json\n","files-import-final/results/ft/small_xsum_128_first.json\n","files-import-final/results/icl/\n","files-import-final/results/icl/med_xsum_1_custom.json\n","files-import-final/results/icl/full_xsum_0_tldr.json\n","files-import-final/results/icl/full_xsum_1_none.json\n","files-import-final/results/icl/med_xsum_0_none.json\n","files-import-final/results/icl/full_xsum_0_none.json\n","files-import-final/results/icl/med_xsum_4_custom.json\n","files-import-final/results/icl/med_xsum_1_tldr.json\n","files-import-final/results/icl/full_xsum_4_tldr.json\n","files-import-final/results/icl/med_xsum_1_none.json\n","files-import-final/results/icl/med_xsum_0_custom.json\n","files-import-final/results/icl/full_xsum_0_custom.json\n","files-import-final/results/icl/med_xsum_4_none.json\n","files-import-final/results/icl/med_xsum_0_tldr.json\n","files-import-final/results/icl/full_xsum_1_custom.json\n","files-import-final/results/icl/full_xsum_1_tldr.json\n","files-import-final/results/icl/full_xsum_4_none.json\n","files-import-final/results/icl/med_xsum_4_tldr.json\n","files-import-final/ft_xsum_[0, 1, 8, 128]_modes.png\n","files-import-final/icl.py\n","files-import-final/ft.py\n","files-import-final/utils.py\n","files-import-final/__pycache__/\n","files-import-final/__pycache__/utils.cpython-310.pyc\n","files-import-final/__pycache__/icl.cpython-310.pyc\n","files-import-final/ft_babi_[0, 1, 8, 128]_modes.png\n","files-import-final/requirements.txt\n","files-import-final/icl_xsum_[0, 1, 4]_['none', 'tldr'].png\n"]}],"source":["!tar -czvf output_2.tar.gz files-import-final"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
